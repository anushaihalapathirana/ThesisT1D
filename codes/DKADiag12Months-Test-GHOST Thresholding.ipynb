{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import sys\n",
    "import numpy\n",
    "import math\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as ltb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectPercentile\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, auc, roc_curve, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(38)\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load pre porcessed data\n",
    "df = pd.read_csv('../prepross_data/data_dka.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filterout the paper described patient set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter dataset as describe in paper\n",
    "def get_filter_by_age_diabDur(df, age, diabDur):\n",
    "    filter_patients = df[(df[\"AgeAtConsent\"] >= age) & (df[\"diagDuration\"] > diabDur)] \n",
    "#     filter_patients=filter_patients.drop_duplicates(subset=\"PtID\",keep=\"first\") \n",
    "    print(f'Number of patients whos age is {age}+ and diabetics duration greater than {diabDur}  is -> {filter_patients.PtID.size}')\n",
    "    return filter_patients\n",
    "\n",
    "df = get_filter_by_age_diabDur(df, 26, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unknown data\n",
    "\n",
    "df.drop(df[df.DKAPast12mos == 2].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[(df['DKAPast12mos'] ==0 ) & (df['Pt_HospDKASinceDiag'] == 0)]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for DKA events prediction pre processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_label = 'DKAPast12mos' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill null value according to the other parameters\n",
    "\n",
    "# fill with 0 - if data not available probably patient has not that medical condition\n",
    "def fill_y_label(row):\n",
    "\n",
    "    if(math.isnan(row['DKAPast12mos'])):\n",
    "        if((row['NumDKAOccur'] >= 1) or (row['Pt_NumHospDKA']>=1)):\n",
    "            row[y_label] = 0\n",
    "        else:\n",
    "            row[y_label] = 1\n",
    "    return row\n",
    "\n",
    "\n",
    "df = df.apply(fill_y_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get possible values in column including nan\n",
    "def get_possible_vals_with_nan(df, colName):\n",
    "    list_val =df[colName].unique().tolist()\n",
    "    return list_val\n",
    "\n",
    "\n",
    "# DKADiag {'1.Yes': 0, '2.Probably Yes': 1, '3.No': 2, '4.Unknown': 3}\n",
    "df['DKADiag'] = df['DKADiag'].replace({1.0: 0.0, 2.0:1.0, 3.0:1.0})\n",
    "\n",
    "get_possible_vals_with_nan(df, 'DKADiag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "\n",
    "def get_missing_val_percentage(df):\n",
    "    return (df.isnull().sum()* 100 / len(df))\n",
    "\n",
    "\n",
    "missing_per = get_missing_val_percentage(df)\n",
    "\n",
    "# get missing values < threshold feature name list\n",
    "variables = df.columns\n",
    "thresh = 40\n",
    "variable = [ ]\n",
    "var = []\n",
    "for i in range(df.columns.shape[0]):\n",
    "    if missing_per[i]<= thresh: #setting the threshold as 40%\n",
    "        variable.append(variables[i])\n",
    "    else :\n",
    "        var.append(variables[i])\n",
    "        \n",
    "print(\"variables missing vals < threshold\")     \n",
    "print(variable)\n",
    "print(\"Length: \", len(variable))\n",
    "\n",
    "print()\n",
    "print(\"variables missing vals > threshold\")     \n",
    "print(var)\n",
    "print(\"Length: \", len(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_del = ['Diab_dur_greater','HbA1C_SH', 'Pt_InsHumalog', 'Pt_InsNovolog', 'Pt_BolusDecCntCarb', \n",
    "#                'Pt_BolusBedtimeSnackFreq', 'Pt_InsPumpStartAge', 'Pt_PumpManuf', 'Pt_PumpModel',\n",
    "#                'Pt_DaysLeavePumpIns', 'Pt_BasInsRateChgDay', 'Pt_NumBolusDay', 'Pt_ReturnPump', \n",
    "#                'Pt_InjMethod', 'Pt_InjLongActDay', 'Pt_InjShortActDay', 'Pt_LongActInsDay', \n",
    "#                'Pt_ShortActInsDay', 'Pt_PumpStopUse', 'Pt_HealthProfDiabEdu', 'Pt_SmokeAmt', \n",
    "#                'Pt_DaysWkEx', 'Pt_MenarcheAge', 'Pt_RegMenstCyc', 'Pt_IrregMenstCycReas',\n",
    "#                'Pt_CurrPreg', 'Pt_MiscarriageNum', 'Pt_v3NumHospOthReas',\n",
    "#                'HyperglyCritRandGluc', 'WeightDiag', 'NumDKAOccur', 'TannerNotDone', 'PumpTotBasIns',\n",
    "#                'HGMNumDays', 'HGMTestCntAvg', 'HGMGlucMean', 'CGMGlucPctBelow70', 'CGMGlucPctBelow60', \n",
    "#                'PulseRate', 'InsCarbRatBrkfst', 'InsCarbRatLunch', 'InsCarbRatDinn', 'InsCarbRatDinnNotUsed', \n",
    "#                'CGMPctBelow55', 'CGMPctBelow80']\n",
    "\n",
    "cols_to_del = ['Diab_dur_greater']\n",
    "\n",
    "\n",
    "df.drop(cols_to_del, inplace=True, axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df.drop('PtID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrX_orig(df, cut = 0.8) :\n",
    "        \n",
    "    # Get correlation matrix and upper triagle\n",
    "    corr_mtx = df.corr().abs()\n",
    "    avg_corr = corr_mtx.mean(axis = 1)\n",
    "    up = corr_mtx.where(np.triu(np.ones(corr_mtx.shape), k=1).astype(np.bool))\n",
    "    \n",
    "    drop = list()\n",
    "    \n",
    "    # For loop implements this pseudocode\n",
    "    # For every cell in the upper triangle: \n",
    "        # If cell.value > 0.6: \n",
    "                # If mean(row_correlation) > mean(column_correlation):drop(column)\n",
    "\t\t# Else: drop(row)\n",
    "        \n",
    "    for row in range(len(up)-1):\n",
    "        col_idx = row + 1\n",
    "        for col in range (col_idx, len(up)):\n",
    "            if(corr_mtx.iloc[row, col] > cut):\n",
    "                if(avg_corr.iloc[row] > avg_corr.iloc[col]): \n",
    "                    drop.append(row)\n",
    "                else: \n",
    "                    drop.append(col)\n",
    "    \n",
    "    drop_set = list(set(drop))\n",
    "    dropcols_names = list(df.columns[[item for item in drop_set]])\n",
    "    \n",
    "    return(dropcols_names)\n",
    "\n",
    "cols_to_drop = corrX_orig(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(['Lipoatrophy',\n",
    " 'AgeAtConsent',\n",
    " 'InsCarbRatDinn',\n",
    " 'InsNovolog',\n",
    " 'CGMGlucPctBelow60'], inplace=True, axis=1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def divide_data(df,label):\n",
    "    Y = df[label]\n",
    "    X = df.drop(label, axis=1)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = divide_data(df, y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape = np.shape(X) \n",
    "feature = 25 #shape[1] \n",
    "n_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed(42)\n",
    "tf.random.set_seed(38)\n",
    "# Save original data set\n",
    "original_X = X\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, stratify=Y, random_state=123)\n",
    "# if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(Y_train == 0.0)\n",
    "unique, counts = numpy.unique(Y_train.to_numpy(), return_counts=True)\n",
    "print(\"Train - \", unique, counts)\n",
    "\n",
    "unique_test, counts_test = numpy.unique(Y_test.to_numpy(), return_counts=True)\n",
    "print(\"Test - \", unique_test, counts_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.bar(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, optimal_idx):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label='Best') \n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use only for XGB classifier with missing values\n",
    "# X_train_copy = X_train.drop(['NumDKAOccur', 'Pt_NumHospDKA'], axis=1)\n",
    "# X_test_copy = X_test.drop(['NumDKAOccur', 'Pt_NumHospDKA'], axis=1)\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "if('NumDKAOccur' in X_train.columns):\n",
    "    X_train_copy = X_train_copy.drop(['NumDKAOccur'], axis=1)\n",
    "    X_test_copy = X_test_copy.drop([ 'NumDKAOccur'], axis=1)\n",
    "if('Pt_NumHospDKA' in X_train.columns):\n",
    "    X_train_copy = X_train_copy.drop(['Pt_NumHospDKA'], axis=1)\n",
    "    X_test_copy = X_test_copy.drop(['Pt_NumHospDKA'], axis=1)\n",
    "# if('Pt_HospDKASinceDiag' in X_train.columns):\n",
    "#     X_train_copy = X_train_copy.drop(['Pt_HospDKASinceDiag'], axis=1)\n",
    "#     X_test_copy = X_test_copy.drop(['Pt_HospDKASinceDiag'], axis=1)\n",
    "\n",
    "\n",
    "# features_set = ['Pt_InitTrt', 'Pt_HospDKASinceDiag',\n",
    "#        'Pt_MissInsDoseFreq', 'Pt_BasInsRateChgDay', 'Pt_NumBolusDay',\n",
    "#        'Pt_NumMeterCheckDay', 'Pt_ChkKetones', 'Pt_LastEyeExamPart',\n",
    "#        'Pt_SmokeAmt', 'Pt_EmployStatus', 'Pt_RaceEth',\n",
    "#        'ExamDaysFromConsent', 'BldPrSys', 'PumpTotBasIns', 'PulseRate',\n",
    "#        'InsCarbRatDinnNotUsed', 'LastEyeExam', 'Pt_v3NumERVisOthReas',\n",
    "#        'Pt_v3NumSHSeizComa', 'HbA1c', 'Psychosis', 'Insulin_Lispro',\n",
    "#        'diagDuration']\n",
    "\n",
    "# X_train_copy = X_train_copy[features_set]\n",
    "# X_test_copy = X_test_copy[features_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits= 3, shuffle=False)\n",
    "train = X_train_copy.copy()\n",
    "train[y_label] = Y_train.values\n",
    "\n",
    "def cross_val_with_missing_val(model):\n",
    "#     i = 1\n",
    "#     for train_index, test_index in kf.split(train):\n",
    "#         X_train1 = train.iloc[train_index].loc[:, X_train.columns]\n",
    "#         X_test1 = train.iloc[test_index][X_train.columns]\n",
    "#         y_train1 = train.iloc[train_index].loc[:,y_label]\n",
    "#         y_test1 = train.iloc[test_index][y_label]\n",
    "\n",
    "#         #Train the model\n",
    "#         model.fit(X_train1, y_train1) #Training the model\n",
    "#         print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test1, model.predict(X_test1))}\")\n",
    "#         i += 1\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "    dfs = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(train, Y_train):\n",
    "        X_train1 = train.iloc[train_index].loc[:, X_train_copy.columns]\n",
    "        X_test1 = train.iloc[test_index].loc[:,X_train_copy.columns]\n",
    "        y_train1 = train.iloc[train_index].loc[:,y_label]\n",
    "        y_test1 = train.iloc[test_index].loc[:,y_label]\n",
    "\n",
    "        #Train the model\n",
    "        model.fit(X_train1, y_train1) #Training the model\n",
    "        print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test1, model.predict(X_test1))}, doublecheck: {model.score(X_test1,y_test1)}\")\n",
    "\n",
    "        # how many occurances appear in the train set\n",
    "        s_train = train.iloc[train_index].loc[:,y_label].value_counts()\n",
    "        s_train.name = f\"train {i}\"\n",
    "        s_test = train.iloc[test_index].loc[:,y_label].value_counts()\n",
    "        s_test.name = f\"test {i}\"\n",
    "        df = pd.concat([s_train, s_test], axis=1, sort=False)\n",
    "        df[\"|\"] = \"|\"\n",
    "        dfs.append(df)\n",
    "\n",
    "        i += 1\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ghostml\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def calc_metrics(labels_test, test_probs, threshold = 0.5):\n",
    "    scores = [1 if x>=threshold else 0 for x in test_probs]\n",
    "   \n",
    "    auc = metrics.roc_auc_score(labels_test, test_probs)\n",
    "    kappa = metrics.cohen_kappa_score(labels_test,scores)\n",
    "    confusion = metrics.confusion_matrix(labels_test,scores, labels=list(set(labels_test)))\n",
    "    \n",
    "    confusion_matrix_xgb_train = pd.DataFrame(confusion)\n",
    "    sns.heatmap(confusion_matrix_xgb_train, annot=True,fmt='g')\n",
    "\n",
    "    print('thresh: %.2f, kappa: %.3f, AUC test-set: %.3f'%(threshold, kappa, auc))\n",
    "    print(confusion)\n",
    "    print(metrics.classification_report(labels_test,scores))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = ltb.LGBMClassifier(use_missing = True,\n",
    "                         learning_rate = 0.1, \n",
    "                         max_depth =5, random_state=0 )\n",
    "    \n",
    "cls.fit(X_train_copy, Y_train)\n",
    "\n",
    "# Get prediction probabilities for the test set\n",
    "test_probs = cls.predict_proba(X_test_copy)[:,1] \n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(Y_test, test_probs, threshold = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the positive prediction probabilities for the training set from the trained RF model\n",
    "train_probs = cls.predict_proba(X_train_copy)[:,1]\n",
    "\n",
    "# optmize the threshold \n",
    "fpr, tpr, thresholds = roc_curve(Y_train, train_probs)\n",
    "# thresholds = np.round(np.arange(0.99001,1.0,0.01),2)\n",
    "#ROC\n",
    "threshold1 = ghostml.optimize_threshold_from_predictions(Y_train,\n",
    "                                                         train_probs, \n",
    "                                                         thresholds,\n",
    "                                                         ThOpt_metrics = 'ROC',\n",
    "                                                         with_replacement=True,\n",
    "                                                         subsets_size = 1000,\n",
    "                                                         N_subsets = 1000) \n",
    "\n",
    "# Print confusion matrix and classification metrics\n",
    "calc_metrics(Y_test, test_probs, threshold = threshold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost - train with missing values\n",
    "\n",
    "model=XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eta = 0.1,#eta between(0.01-0.2)\n",
    "        max_depth = 4, #values between(3-10)\n",
    "#         max_delta_step = 10,\n",
    "# # #         scale_pos_weight = 0.4,\n",
    "# # #         n_jobs = 0,\n",
    "#         subsample = 0.5,#values between(0.5-1)\n",
    "#         colsample_bytree = 1,#values between(0.5-1)\n",
    "#         tree_method = \"auto\",\n",
    "#         process_type = \"default\",\n",
    "#         num_parallel_tree=7,\n",
    "        objective='multi:softmax',\n",
    "# #         min_child_weight = 3,\n",
    "        booster='gbtree',\n",
    "        eval_metric = \"mlogloss\",\n",
    "        num_class = n_classes\n",
    "    )\n",
    "                   \n",
    "# model.fit(X_train_copy,Y_train)\n",
    "model = cross_val_with_missing_val(model)\n",
    "\n",
    "# xgb_pred=model.predict(X_test_copy)\n",
    "# xgb_pred_train=model.predict(X_train_copy)\n",
    "\n",
    "print(\"\\n \\n ===========   Train Dataset    =============\")\n",
    "\n",
    "\n",
    "y_scores1 = model.predict_proba(X_train_copy)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_train, y_scores1)\n",
    "print(\"train ROC score\", roc_auc_score(Y_train, y_scores1))\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "plot_roc_curve(fpr, tpr,optimal_idx)\n",
    "\n",
    "xgb_pred_train = (model.predict_proba(X_train_copy)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score(Y_train, xgb_pred_train)*100)\n",
    "\n",
    "confusion_matrix_xgb_train = pd.DataFrame(confusion_matrix(Y_train, xgb_pred_train))\n",
    "sns.heatmap(confusion_matrix_xgb_train, annot=True,fmt='g')\n",
    "\n",
    "print(classification_report(Y_train, xgb_pred_train))\n",
    "plt.show()\n",
    "\n",
    "train_acc = model.score(X_train_copy, Y_train)\n",
    "print('Accuracy of XGB on training set: {:.2f}'.format(train_acc))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n ===========   Test Dataset    =============\")\n",
    "# find optimal threshold\n",
    "y_scores = model.predict_proba(X_test_copy)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_scores)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "plot_roc_curve(fpr, tpr, optimal_idx)\n",
    "\n",
    "xgb_pred = (model.predict_proba(X_test_copy)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score(Y_test, xgb_pred)*100)\n",
    "\n",
    "confusion_matrix_xgb = confusion_matrix(Y_test, xgb_pred)\n",
    "sns.heatmap(confusion_matrix_xgb, annot=True, fmt='g')\n",
    "\n",
    "print(classification_report(Y_test, xgb_pred))\n",
    "plt.show()\n",
    "\n",
    "test_acc = model.score(X_test_copy, Y_test)\n",
    "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "     .format(test_acc))\n",
    "\n",
    "# ROC\n",
    "print(\"\\n\\n ===========   ROC    =============\")\n",
    "\n",
    "y_scores = model.predict_proba(X_test_copy)\n",
    "score = roc_auc_score(Y_test, y_scores[:, 1])\n",
    "score = round(score,4)\n",
    "print(f'roc_auc = {score}')\n",
    "\n",
    "\n",
    "print(\"\\n\\n ===========   Class-wise test accuracy    =============\")\n",
    "acc = confusion_matrix_xgb.diagonal()/confusion_matrix_xgb.sum(axis=1)\n",
    "print('classwise accuracy [class 0, class 1]: ', acc)\n",
    "print('average accuracy: ',  np.sum(acc)/2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance graph of XGB\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X_train_copy.columns[0:250])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM Classifier with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xgboost - train with missing values\n",
    "\n",
    "model=ltb.LGBMClassifier(use_missing = True,\n",
    "                         learning_rate = 0.1, \n",
    "                         max_depth =5, random_state=0 )\n",
    "                   \n",
    "# model.fit(X_train_copy,Y_train)\n",
    "model = cross_val_with_missing_val(model)\n",
    "\n",
    "# xgb_pred=model.predict(X_test_copy)\n",
    "# xgb_pred_train=model.predict(X_train_copy)\n",
    "\n",
    "print(\"\\n \\n ===========   Train Dataset    =============\")\n",
    "\n",
    "\n",
    "y_scores1 = model.predict_proba(X_train_copy)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_train, y_scores1)\n",
    "print(\"train ROC score\", roc_auc_score(Y_train, y_scores1))\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "plot_roc_curve(fpr, tpr,optimal_idx)\n",
    "xgb_pred_train = (model.predict_proba(X_train_copy)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score(Y_train, xgb_pred_train)*100)\n",
    "\n",
    "confusion_matrix_xgb_train = pd.DataFrame(confusion_matrix(Y_train, xgb_pred_train))\n",
    "sns.heatmap(confusion_matrix_xgb_train, annot=True,fmt='g')\n",
    "\n",
    "print(classification_report(Y_train, xgb_pred_train))\n",
    "plt.show()\n",
    "\n",
    "train_acc = model.score(X_train_copy, Y_train)\n",
    "print('Accuracy of XGB on training set: {:.2f}'.format(train_acc))\n",
    "\n",
    "\n",
    "print(\"\\n\\n ===========   Test Dataset    =============\")\n",
    "# find optimal threshold\n",
    "y_scores = model.predict_proba(X_test_copy)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_scores)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)\n",
    "plot_roc_curve(fpr, tpr, optimal_idx)\n",
    "\n",
    "xgb_pred = (model.predict_proba(X_test_copy)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score(Y_test, xgb_pred)*100)\n",
    "\n",
    "confusion_matrix_xgb = confusion_matrix(Y_test, xgb_pred)\n",
    "sns.heatmap(confusion_matrix_xgb, annot=True, fmt='g')\n",
    "\n",
    "print(classification_report(Y_test, xgb_pred))\n",
    "plt.show()\n",
    "\n",
    "test_acc = model.score(X_test_copy, Y_test)\n",
    "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "     .format(test_acc))\n",
    "\n",
    "# ROC\n",
    "print(\"\\n\\n ===========   ROC    =============\")\n",
    "\n",
    "y_scores = model.predict_proba(X_test_copy)\n",
    "score = roc_auc_score(Y_test, y_scores[:, 1])\n",
    "score = round(score,4)\n",
    "print(f'roc_auc = {score}')\n",
    "\n",
    "\n",
    "print(\"\\n\\n ===========   Class-wise test accuracy    =============\")\n",
    "acc = confusion_matrix_xgb.diagonal()/confusion_matrix_xgb.sum(axis=1)\n",
    "print('classwise accuracy [class 0, class 1]: ', acc)\n",
    "print('average accuracy: ',  np.sum(acc)/2)\n",
    "\n",
    "\n",
    "print('f1', metrics.f1_score(xgb_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance graph of XGB\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X_train_copy.columns[0:250])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.update(X_train[[\n",
    "             'Pt_InsPriv','Pt_BolusDecCntCarb', 'Pt_HealthProfDiabEdu',\n",
    "             'Pt_MiscarriageNum','HyperglyCritRandGluc','NumDKAOccur','TannerNotDone',\n",
    "             'Pt_InsLev1PerDay','Pt_InsLev2PerDay','Pt_InsLant1PerDay','Pt_InsLant2PerDay'\n",
    "             ]].fillna(0))\n",
    "\n",
    "X_test.update(X_test[[\n",
    "             'Pt_InsPriv','Pt_BolusDecCntCarb', 'Pt_HealthProfDiabEdu',\n",
    "             'Pt_MiscarriageNum','HyperglyCritRandGluc','NumDKAOccur','TannerNotDone',\n",
    "             'Pt_InsLev1PerDay','Pt_InsLev2PerDay','Pt_InsLant1PerDay','Pt_InsLant2PerDay'\n",
    "             ]].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill nan values in categorical dataset with frequent value\n",
    "\n",
    "# tested wuth mean and median - results is lower than most_frequent\n",
    "imputeX = SimpleImputer(missing_values=np.nan, strategy = \"most_frequent\")\n",
    "# imputeX = KNNImputer(missing_values=np.nan, n_neighbors = 3, weights='distance')\n",
    "# imputeX = IterativeImputer(max_iter=5, random_state=0)\n",
    "\n",
    "X_train = imputeX.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test data imputation\n",
    "\n",
    "Test = X_test.copy()\n",
    "Test.loc[:,y_label] = Y_test\n",
    "\n",
    "X_test = imputeX.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "select = {}\n",
    "select[0] = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "select[1] = Y_train\n",
    "select[2] = pd.DataFrame(scaler.transform(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# def select_features(select, feature):\n",
    "#     selected = {}\n",
    "#     fs = SelectKBest(score_func=mutual_info_classif, k=feature) # k=feature score_func SelectPercentile\n",
    "#     selected[0] = fs.fit_transform(select[0], select[1])\n",
    "#     selected[1] = fs.transform(select[2])\n",
    "        \n",
    "#     idx = fs.get_support(indices=True)\n",
    "    \n",
    "#     return selected, fs, idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Selecting the Best important features according to Logistic Regression\n",
    "# Give better performance than selectKBest \n",
    "def select_features(select, feature):\n",
    "    selected = {}\n",
    "#     fs = RFE(estimator=LogisticRegression(), n_features_to_select=feature, step = 1) #  step (the number of features eliminated each iteration) \n",
    "    fs = RFE(estimator=XGBClassifier(), n_features_to_select=feature, step = 5) #  step (the number of features eliminated each iteration) \n",
    "#     fs = RFE(estimator=RandomForestClassifier(), n_features_to_select=feature, step = 1) #  step (the number of features eliminated each iteration) \n",
    "    \n",
    "    \n",
    "    selected[0] = fs.fit_transform(select[0], select[1])\n",
    "    selected[1] = fs.transform(select[2])\n",
    "        \n",
    "    idx = fs.get_support(indices=True)\n",
    "    \n",
    "    return selected, fs, idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "selected, fs, idx = select_features(select, feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns to keep and create new dataframe with those only\n",
    "from pprint import pprint\n",
    "cols = fs.get_support(indices=True)\n",
    "features_df_new = original_X.iloc[:,cols]\n",
    "pprint(features_df_new.columns)\n",
    "print(features_df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(selected[0], columns = features_df_new.columns)\n",
    "X_test = pd.DataFrame(selected[1], columns = features_df_new.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if('NumDKAOccur' in X_train.columns):\n",
    "    X_train = X_train.drop(['NumDKAOccur'], axis=1)\n",
    "    X_test = X_test.drop([ 'NumDKAOccur'], axis=1)\n",
    "if('Pt_NumHospDKA' in X_train.columns):\n",
    "    X_train = X_train.drop(['Pt_NumHospDKA'], axis=1)\n",
    "    X_test = X_test.drop([ 'Pt_NumHospDKA'], axis=1)\n",
    "# if('Pt_HospDKASinceDiag' in X_train.columns):\n",
    "#     X_train = X_train.drop(['Pt_HospDKASinceDiag'], axis=1)\n",
    "#     X_test = X_test.drop([ 'Pt_HospDKASinceDiag'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits= 3, shuffle=False)\n",
    "train = X_train.copy()\n",
    "train[y_label] = Y_train.values\n",
    "\n",
    "def cross_val(model):\n",
    "#     i = 1\n",
    "#     for train_index, test_index in kf.split(train):\n",
    "#         X_train1 = train.iloc[train_index].loc[:, X_train.columns]\n",
    "#         X_ test1 = train.iloc[test_index][X_train.columns]\n",
    "#         y_train1 = train.iloc[train_index].loc[:,y_label]\n",
    "#         y_test1 = train.iloc[test_index][y_label]\n",
    "\n",
    "#         #Train the model\n",
    "#         model.fit(X_train1, y_train1) #Training the model\n",
    "#         print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test1, model.predict(X_test1))}\")\n",
    "#         i += 1\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "    dfs = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(train, Y_train):\n",
    "        X_train1 = train.iloc[train_index].loc[:, X_train.columns]\n",
    "        X_test1 = train.iloc[test_index].loc[:,X_train.columns]\n",
    "        y_train1 = train.iloc[train_index].loc[:,y_label]\n",
    "        y_test1 = train.iloc[test_index].loc[:,y_label]\n",
    "\n",
    "        #Train the model\n",
    "        model.fit(X_train1, y_train1) #Training the model\n",
    "        print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test1, model.predict(X_test1))}, doublecheck: {model.score(X_test1,y_test1)}\")\n",
    "\n",
    "        # how many occurances appear in the train set\n",
    "        s_train = train.iloc[train_index].loc[:,y_label].value_counts()\n",
    "        s_train.name = f\"train {i}\"\n",
    "        s_test = train.iloc[test_index].loc[:,y_label].value_counts()\n",
    "        s_test.name = f\"test {i}\"\n",
    "        df = pd.concat([s_train, s_test], axis=1, sort=False)\n",
    "        df[\"|\"] = \"|\"\n",
    "        dfs.append(df)\n",
    "\n",
    "        i += 1\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_thresh(model, X, Y):\n",
    "    y_scores = model.predict_proba(X)[:,1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(Y, y_scores)\n",
    "    print(roc_auc_score(Y, y_scores))\n",
    "#     optimal_idx = np.argmax(sqrt(tpr * (1-fpr)))\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(\"Threshold value is:\", optimal_threshold)\n",
    "    plot_roc_curve(fpr, tpr, optimal_idx)\n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_results(model, X_train, Y_train, pred_train):\n",
    "    print(\"\\n \\n =====================   Train Dataset    ======================\")\n",
    "\n",
    "    print(accuracy_score(Y_train, pred_train)*100)\n",
    "\n",
    "    confusion_matrix_train = pd.DataFrame(confusion_matrix(Y_train, pred_train))\n",
    "    sns.heatmap(confusion_matrix_train, annot=True,fmt='g')\n",
    "    print(classification_report(Y_train, pred_train))\n",
    "    plt.show()\n",
    "    \n",
    "    train_acc = model.score(X_train, Y_train)\n",
    "    print('Accuracy of on training set: {:.2f}'.format(train_acc))\n",
    "\n",
    "def test_results(model, X_test, Y_test, pred):\n",
    "    print(\"\\n\\n =====================   Test Dataset    =======================\")\n",
    "\n",
    "    print(accuracy_score(Y_test, pred)*100)\n",
    "\n",
    "    confusion_matrix_model = confusion_matrix(Y_test, pred)\n",
    "    sns.heatmap(confusion_matrix_model, annot=True,fmt='g')\n",
    "    print(classification_report(Y_test, pred))\n",
    "    plt.show()\n",
    "    \n",
    "    test_acc = model.score(X_test, Y_test)\n",
    "    print('Accuracy of classifier on test set: {:.2f}'\n",
    "         .format(test_acc))\n",
    "\n",
    "def ROC_results(model, X_test, Y_test):\n",
    "    print(\"\\n\\n =======================   Test-ROC    =========================\")\n",
    "\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    score = roc_auc_score(Y_test, y_scores[:, 1])\n",
    "    score = round(score,4)\n",
    "    print(f'roc_auc = {score}')\n",
    "    \n",
    "def class_wise_test_accuracy(model, Y_test, pred):\n",
    "    print(\"\\n\\n =======================   Class-wise test accuracy    =====================\")\n",
    "    confusion_matrix_model = confusion_matrix(Y_test, pred)\n",
    "    acc = confusion_matrix_model.diagonal()/confusion_matrix_model.sum(axis=1)\n",
    "    print('classwise accuracy [class 0, class 1]: ',(acc))\n",
    "    print('average accuracy: ',( np.sum(acc)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score\n",
    "\n",
    "ltb_model = ltb.LGBMClassifier(use_missing = False,\n",
    "                         learning_rate = 0.01, \n",
    "                         max_depth =5, random_state=0 )\n",
    "# ltb_model.fit(X_train, Y_train)\n",
    "ltb_model = cross_val(ltb_model)\n",
    "\n",
    "# pred=ltb_model.predict(X_test)\n",
    "# pred_train=ltb_model.predict(X_train)\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(ltb_model, X_test, Y_test)\n",
    "pred = (ltb_model.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "optimal_threshold_train= optimal_thresh(ltb_model, X_train, Y_train)\n",
    "pred_train = (ltb_model.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "# test and train results\n",
    "train_results(ltb_model, X_train, Y_train, pred_train)\n",
    "test_results(ltb_model, X_test, Y_test, pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(ltb_model, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(ltb_model, Y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(ltb_model.feature_importances_, index=X_train.columns[0:feature])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=0, learning_rate=0.05, n_estimators=1000, algorithm = \"SAMME.R\") #algorithm{‘SAMME’, ‘SAMME.R’}, default=’SAMME.R’\n",
    "\n",
    "# adaboost.fit(X_train, Y_train)\n",
    "adaboost = cross_val(adaboost)\n",
    "\n",
    "# pred=adaboost.predict(X_test)\n",
    "# pred_train=adaboost.predict(X_train)\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(adaboost, X_test, Y_test)\n",
    "pred = (adaboost.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "optimal_threshold_train= optimal_thresh(adaboost, X_train, Y_train)\n",
    "pred_train = (adaboost.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "# test and train results\n",
    "train_results(adaboost, X_train, Y_train, pred_train)\n",
    "test_results(adaboost, X_test, Y_test, pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(adaboost, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(adaboost, Y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(adaboost.feature_importances_, index=X_train.columns[0:feature])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost - train with missing values\n",
    "\n",
    "\n",
    "xgb_impute=XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eta = 0.1,#eta between(0.01-0.2)\n",
    "        max_depth = 4, #values between(3-10)\n",
    "#         max_delta_step = 10,\n",
    "#         subsample = 0.5,#values between(0.5-1)\n",
    "#         colsample_bytree = 1,#values between(0.5-1)\n",
    "#         tree_method = \"auto\",\n",
    "#         process_type = \"default\",\n",
    "#         num_parallel_tree=7,\n",
    "        objective='multi:softmax',\n",
    "#         min_child_weight = 3,\n",
    "        booster='gbtree',\n",
    "        eval_metric = \"mlogloss\",\n",
    "        num_class = n_classes\n",
    "        )\n",
    "        \n",
    "# xgb_impute.fit(X_train,Y_train)\n",
    "xgb_impute = cross_val(xgb_impute)\n",
    "\n",
    "# xgb_pred=xgb_impute.predict(X_test)\n",
    "# xgb_pred_train=xgb_impute.predict(X_train)\n",
    "\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(xgb_impute, X_test, Y_test)\n",
    "optimal_threshold_train= optimal_thresh(xgb_impute, X_train, Y_train)\n",
    "\n",
    "xgb_pred = (xgb_impute.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "xgb_pred_train = (xgb_impute.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "\n",
    "train_results(xgb_impute, X_train, Y_train, xgb_pred_train)\n",
    "test_results(xgb_impute, X_test, Y_test, xgb_pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(xgb_impute, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(xgb_impute, Y_test, xgb_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature importance graph of XGB\n",
    "feat_importances = pd.Series(xgb_impute.feature_importances_, index=X_train.columns[0:feature])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  random forest classifier\n",
    "\n",
    "rf=RandomForestClassifier(max_depth=5,\n",
    "#                              n_estimators = feature,\n",
    "                             criterion = 'gini', # {“gini”, “entropy”}, default=”gini”\n",
    "                             class_weight = 'balanced_subsample', # {“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "                             ccp_alpha=0.01,\n",
    "                             random_state=0)\n",
    "\n",
    "# rf.fit(X_train,Y_train)\n",
    "rf = cross_val(rf)\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(rf, X_test, Y_test)\n",
    "optimal_threshold_train= optimal_thresh(rf, X_train, Y_train)\n",
    "\n",
    "# pred=rf.predict(X_test)\n",
    "pred = (rf.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "\n",
    "# pred_train=rf.predict(X_train)\n",
    "pred_train = (rf.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "\n",
    "train_results(rf, X_train, Y_train, pred_train)\n",
    "test_results(rf, X_test, Y_test, pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(rf, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(rf, Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index=X_train.columns[0:feature])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "logreg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    tol = 5e-4,\n",
    "    C=1,\n",
    "    l1_ratio = 10,\n",
    "    class_weight='balanced',  # balanced\n",
    "    random_state=0,\n",
    "    solver = 'saga' # saga, sag\n",
    ")\n",
    "\n",
    "# logreg.fit(X_train, Y_train)\n",
    "logreg = cross_val(logreg)\n",
    "\n",
    "# pred=logreg.predict(X_test)\n",
    "# pred_train=logreg.predict(X_train)\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(logreg, X_test, Y_test)\n",
    "optimal_threshold_train= optimal_thresh(logreg, X_train, Y_train)\n",
    "\n",
    "pred = (logreg.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "pred_train = (logreg.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "train_results(logreg, X_train, Y_train, pred_train)\n",
    "test_results(logreg, X_test, Y_test, pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(logreg, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(logreg, Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "feat_importances = pd.Series(logreg.coef_[0], index=X_train.columns[0:feature])\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6 - Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda = LinearDiscriminantAnalysis(\n",
    "    solver = 'eigen', # solver{‘svd’, ‘lsqr’, ‘eigen’}, default=’svd’\n",
    "    shrinkage= 'auto', #shrinkage‘auto’ or float, default=None\n",
    "    n_components = 1,\n",
    "    tol = 1e-3                       \n",
    ")\n",
    "# lda.fit(X_train, Y_train)\n",
    "lda = cross_val(lda)\n",
    "\n",
    "# pred=lda.predict(X_test)\n",
    "# pred_train=lda.predict(X_train)\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(lda, X_test, Y_test)\n",
    "optimal_threshold_train= optimal_thresh(lda, X_train, Y_train)\n",
    "\n",
    "pred = (lda.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "pred_train = (lda.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "train_results(lda, X_train, Y_train, pred_train)\n",
    "test_results(lda, X_test, Y_test, pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(lda, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(lda, Y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7- Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=gnb, param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "# nbModel_grid.fit(X_train, Y_train)\n",
    "nbModel_grid = cross_val(nbModel_grid)\n",
    "\n",
    "# best parameters\n",
    "print(nbModel_grid.best_estimator_)\n",
    "\n",
    "gnb = GaussianNB(priors=None, var_smoothing=1.0)\n",
    "gnb.fit(X_train, Y_train)\n",
    "      \n",
    "# pred=gnb.predict(X_test)\n",
    "# pred_train=gnb.predict(X_train)\n",
    "\n",
    "# find optimal threshold\n",
    "optimal_threshold = optimal_thresh(gnb, X_test, Y_test)\n",
    "optimal_threshold_train= optimal_thresh(gnb, X_train, Y_train)\n",
    "\n",
    "pred = (gnb.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "pred_train = (gnb.predict_proba(X_train)[:,1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "\n",
    "train_results(gnb, X_train, Y_train, pred_train)\n",
    "test_results(gnb, X_test, Y_test, pred)\n",
    "\n",
    "# ROC\n",
    "ROC_results(gnb, X_test, Y_test)\n",
    "\n",
    "# class wise accuracy\n",
    "class_wise_test_accuracy(gnb, Y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(Y_test).head(100)\n",
    "# s = d[d.DKAPast12mos == 0.0]\n",
    "# for index, row in d.iterrows():\n",
    "#     if row.DKAPast12mos == 0.0:\n",
    "#         print(index)\n",
    "d      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "my_model = RandomForestClassifier(random_state=0).fit(X_train, Y_train)\n",
    "\n",
    "row_to_show = 100\n",
    "data_for_prediction = X_test.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "\n",
    "pred = my_model.predict(data_for_prediction_array)\n",
    "print('predictoin', pred)\n",
    "print('actial', Y_test.iloc[row_to_show])\n",
    "my_model.predict_proba(data_for_prediction_array)\n",
    "\n",
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(data_for_prediction)\n",
    "\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# The shap_values object above is a list with two arrays.\n",
    "# The first array is the SHAP values for a negative outcome (have disease), \n",
    "# second array is the list of SHAP values for the positive outcome (don't have the disease).\n",
    "# SHAP values for positive outcomes (pulling out shap_values[1]).\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "NOTE: How do you interpret shap\n",
    "\n",
    "We predicted 0.7, whereas the base_value is 0.4979. Feature values causing increased predictions are in pink, and their visual size shows the magnitude of the feature's effect. Feature values decreasing the prediction are in blue. The biggest impact comes from weight being -0.9503. Though the pt_hospDKASinceDiag value has a meaningful effect decreasing the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
