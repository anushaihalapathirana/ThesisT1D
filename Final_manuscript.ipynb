{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, auc, roc_curve, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tensorflow.python.keras.utils import losses_utils\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "print('Libraries Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to load the dataset and separate features from response, and exclude certain columns\n",
    "def load_dataset(filename, response_col, exclude_cols, which, perc):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    data =  pd.read_csv(filename ,sep = ';',decimal = ',', encoding = 'unicode_escape', engine ='python')\n",
    "    #exclude columns that need to be excluded\n",
    "    data = data.drop(exclude_cols, axis=1)\n",
    "    #convert all \"object\" columns to numeric (according to data description !!)\n",
    "    to_convert = data.select_dtypes('object').columns\n",
    "    data.loc[:,to_convert] = data[to_convert].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "    \n",
    "    if which == 0:\n",
    "        #eliminate class 3\n",
    "        data = data[data[response_col] < 3]\n",
    "    elif which == 1:\n",
    "        #merge class 1 and 2\n",
    "        for i in range(0,len(data)):\n",
    "            if data[response_col][i] == 1:\n",
    "                data.loc[i, response_col] = 2\n",
    "    elif which == 2:\n",
    "        #merge class 1, 2 and 3\n",
    "        for i in range(0,len(data)):\n",
    "            if data[response_col][i] == 1 or data[response_col][i] == 2:\n",
    "                data.loc[i, response_col] = 3\n",
    "    else:\n",
    "        data = data\n",
    "    #delete rows with na\n",
    "    min_count = int(((100-perc)/100)*data.shape[0] + 1)\n",
    "    data = data.dropna(axis = 1, how = 'any', thresh = min_count, subset = None, inplace = False)\n",
    "#     data['index'] = data.index\n",
    "    # split into input (X) and output (y) variables\n",
    "    data = data.dropna()\n",
    "    X = data[data.columns.difference([response_col])]\n",
    "    if which == 0:\n",
    "        y = data[response_col] -2  #made the output from 0 to 1 \n",
    "    elif which == 1:\n",
    "        y = data[response_col] -2 #made the output from 0 to 1 (0 for class three and 1 for 1 and 2)\n",
    "    elif which == 2:\n",
    "        y = data[response_col] -3\n",
    "    else:\n",
    "        y = data[response_col] -1\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 1 # 0 for 1 vs 2, 1 for 3 vs rest, 2 for c3 (1+2+3 vs 4), else/3 for exact import\n",
    "perc = 40\n",
    "\n",
    "# data, X, Y = load_dataset('/home/gunjan28/Documents/UEF/input/HTx_trajektoridata_030921.csv', \"c1\", \n",
    "#                            [\"t2d_diag\",\"c2\",\"c3\",\"t2d_vuosi\", \"aika_diag\", \"pkrea_mitt\", \"hba1c_mitt\", \n",
    "#                             \"ldl_mitt\", \"bmi_mitt\", \"ei_mitaan0\",\"pkrea_luo\",\"ldl_luo\",\"pelkka_ins0\",\"te_takk\",\n",
    "#                             'bmi',\"viimeisin_tk\",\"yleisin_tk\",\"c1_cprob1\",\"c1_cprob2\", \"c1_cprob3\", \"c2_cprob1\",\n",
    "#                             \"c2_cprob2\", \"c2_cprob3\", \"c2_cprob4\",\"ï»¿id\",\"c3_prob1\",\"c3_prob2\",\"c3_prob3\",\n",
    "#                             \"c3_prob4\",\"D10A\",\"G02B\",\"H05A\",\"J04B\",\"J06B\",\"L01A\",\"M01C\",\"N06B\",\"N07X\",\n",
    "#                             \"bmi_mitt_old\"], which, perc)\n",
    "\n",
    "# data, X, Y = load_dataset('/home/gunjan28/Documents/UEF/input/HTx_trajektoridata_030921.csv', \"c1\",\n",
    "#                           [\"c2\",\"c3\",\"ï»¿id\",\n",
    "#                            \"t2d_diag\",\"viimeisin_tk\",\"yleisin_tk\",\n",
    "#                            \"c1_cprob1\",\"c1_cprob2\", \"c1_cprob3\",\n",
    "#                            \"c2_cprob1\",\"c2_cprob2\", \"c2_cprob3\", \"c2_cprob4\",\n",
    "#                            \"c3_prob1\",\"c3_prob2\",\"c3_prob3\",\"c3_prob4\",\n",
    "#                            \"D10A\",\"G02B\",\"H05A\",\"J04B\",\"J06B\",\"L01A\",\"M01C\",\"N06B\",\"N07X\",\"bmi_mitt_old\"],\n",
    "#                             which, perc)\n",
    "\n",
    "data, X, Y = load_dataset('/home/gunjan28/Documents/UEF/input/HTx_trajektoridata_updated_131021.csv', \"c4\",\n",
    "                          [\"c5\",\"ï»¿ID\",\"c4_p1\",\"c4_p2\",\"c4_p3\",\n",
    "                           \"c5_p1\",\"c5_p2\",\"c5_p3\",\"c5_p4\",\n",
    "                           \"D10A\",\"G02B\",\"H05A\",\"J04B\",\"J06B\",\"L01A\",\"M01C\",\"N06B\",\"N07X\"],\n",
    "                            which, perc)\n",
    "\n",
    "# \"c4_p1\",\"c4_p2\",\"c4_p3\",\n",
    "\n",
    "print(Counter(Y))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities = data.loc[:,['c4_p1','c4_p2','c4_p3']]\n",
    "# probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.isna().sum().reset_index(name = 'n').plot.bar(x = 'index', y = 'n', rot = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correlation\n",
    "# X = pd.DataFrame(X)\n",
    "# # corr = X.corr(method ='pearson')\n",
    "\n",
    "# # corr = X.corr(method ='pearson').abs()\n",
    "# corr = X.corr(method ='spearman').abs()\n",
    "# avg_corr = corr.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# print(pd.DataFrame(corr.loc['viim_hba1c_bl']))\n",
    "# pd.set_option(\"display.max_rows\", 11, \"display.max_columns\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = plt.figure(figsize=(19, 15))\n",
    "# plt.matshow(corr, fignum=f.number)\n",
    "# cb = plt.colorbar()\n",
    "# cb.ax.tick_params(labelsize=14)\n",
    "# plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper_tri = corr.where(np.triu(np.ones(corr.shape),k=1).astype(np.bool))\n",
    "# # print(upper_tri)\n",
    "# to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.4)] #8\n",
    "# print(to_drop)\n",
    "# print(len(to_drop))\n",
    "# # X = X.drop(X[to_drop], axis=1)\n",
    "# data = data.drop(data[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrX_new(df, cut = 0.4) :\n",
    "       \n",
    "    # Get correlation matrix and upper triagle\n",
    "    corr_mtx = df.corr().abs()\n",
    "    avg_corr = corr_mtx.mean(axis = 1)\n",
    "    up = corr_mtx.where(np.triu(np.ones(corr_mtx.shape), k=1).astype(np.bool))\n",
    "    \n",
    "    dropcols = list()\n",
    "    \n",
    "    res = pd.DataFrame(columns=(['v1', 'v2', 'v1.target', \n",
    "                                 'v2.target','corr', 'drop' ]))\n",
    "    \n",
    "    for row in range(len(up)-1):\n",
    "        col_idx = row + 1\n",
    "        for col in range (col_idx, len(up)):\n",
    "            if(corr_mtx.iloc[row, col] > cut):\n",
    "                if(avg_corr.iloc[row] > avg_corr.iloc[col]): \n",
    "                    dropcols.append(row)\n",
    "                    drop = corr_mtx.columns[row]\n",
    "                else: \n",
    "                    dropcols.append(col)\n",
    "                    drop = corr_mtx.columns[col]\n",
    "                \n",
    "                s = pd.Series([ corr_mtx.index[row],\n",
    "                up.columns[col],\n",
    "                avg_corr[row],\n",
    "                avg_corr[col],\n",
    "                up.iloc[row,col],\n",
    "                drop],\n",
    "                index = res.columns)\n",
    "        \n",
    "                res = res.append(s, ignore_index = True)\n",
    "    \n",
    "    dropcols_names = calcDrop(res)\n",
    "    \n",
    "    return(dropcols_names)\n",
    "\n",
    "def calcDrop(res):\n",
    "    # All variables with correlation > cutoff\n",
    "    all_corr_vars = list(set(res['v1'].tolist() + res['v2'].tolist()))\n",
    "    \n",
    "    # All unique variables in drop column\n",
    "    poss_drop = list(set(res['drop'].tolist()))\n",
    "\n",
    "    # Keep any variable not in drop column\n",
    "    keep = list(set(all_corr_vars).difference(set(poss_drop)))\n",
    "     \n",
    "    # Drop any variables in same row as a keep variable\n",
    "    p = res[ res['v1'].isin(keep)  | res['v2'].isin(keep) ][['v1', 'v2']]\n",
    "    q = list(set(p['v1'].tolist() + p['v2'].tolist()))\n",
    "    drop = (list(set(q).difference(set(keep))))\n",
    "\n",
    "    # Remove drop variables from possible drop \n",
    "    poss_drop = list(set(poss_drop).difference(set(drop)))\n",
    "    \n",
    "    # subset res dataframe to include possible drop pairs\n",
    "    m = res[ res['v1'].isin(poss_drop)  | res['v2'].isin(poss_drop) ][['v1', 'v2','drop']]\n",
    "        \n",
    "    # remove rows that are decided (drop), take set and add to drops\n",
    "    more_drop = set(list(m[~m['v1'].isin(drop) & ~m['v2'].isin(drop)]['drop']))\n",
    "    for item in more_drop:\n",
    "        drop.append(item)\n",
    "         \n",
    "    return drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_new = corrX_new(X, cut = 0.4)\n",
    "print(len(drop_new))\n",
    "print(drop_new)\n",
    "X = X.drop(drop_new, axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection (MI) Try: Sequential forward/floating/backward selection\n",
    "def select_features(select, feature, NN = True):\n",
    "    selected = {}\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=feature)\n",
    "    selected[0] = fs.fit_transform(select[0], select[1])\n",
    "    selected[1] = fs.transform(select[2])\n",
    "    if NN == True:\n",
    "        selected[2] = fs.transform(select[3])\n",
    "    \n",
    "    idx = fs.get_support(indices=True)\n",
    "    \n",
    "    return selected, fs, idx\n",
    "\n",
    "def create_custom_model(input_dim, output_dim, nodes, n=1, name='model'):\n",
    "#     print(n)\n",
    "    def create_model():\n",
    "        # Create model\n",
    "        model = Sequential(name=name)\n",
    "        for i in range(n):\n",
    "            model.add(Dense(nodes, input_dim=input_dim, activation='sigmoid'))\n",
    "        model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss=loss_fn, \n",
    "                      optimizer='SGD', # 'RMSprop', #'adam', \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    return create_model\n",
    "\n",
    "def classification_repo(true, pred):\n",
    "    for i in range(layer_1_2-layer_1_1):\n",
    "        print(\"Classification report for model with {} hidden layers\".format(i+layer_1_1))\n",
    "        print(classification_report(true, pred[i]))\n",
    "        \n",
    "#confusion matrix\n",
    "def conf_mat(true,pred):\n",
    "    for i in range(layer_1_2-layer_1_1):\n",
    "        print(\"Confussion matrix for model with {} hidden layers\".format(i+layer_1_1))\n",
    "        confusion_matrix_df = pd.DataFrame(confusion_matrix(true, pred[i]))\n",
    "        plt.figure()\n",
    "        sns.heatmap(confusion_matrix_df, annot=True)\n",
    "        plt.show()\n",
    "        # print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.shape(X)\n",
    "feature = 50# shape[1]\n",
    "layer_1_1 = 1\n",
    "layer_1_2 = 2\n",
    "bs = 16\n",
    "epochs = 100\n",
    "nodes = 1024/4 #1024/4\n",
    "sample = 0\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(67)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(38)\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Save original data set\n",
    "original = X\n",
    "\n",
    "# data = data[data.columns.difference(['c4'])]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, stratify=Y)\n",
    "\n",
    "# prob_test = X_test[[\"c4_p1\",\"c4_p2\",\"c4_p3\"]]\n",
    "# X_test = X_test[X_test.columns.difference([\"c4_p1\",\"c4_p2\",\"c4_p3\"])]\n",
    "# X_train = X_train[X_train.columns.difference([\"c4_p1\",\"c4_p2\",\"c4_p3\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "Train = X_train.copy()\n",
    "Train.loc[:,'c4'] = Y_train\n",
    "\n",
    "datasets= {}\n",
    "by_class = Train.groupby('c4')\n",
    "for groups, data in by_class:\n",
    "    datasets[groups] = data\n",
    "\n",
    "X_train_0 = datasets[0][datasets[0].columns.difference(['c4'])]\n",
    "Y_train_0 = datasets[0].loc[:,'c4'].copy()\n",
    "X_train_1 = datasets[1][datasets[1].columns.difference(['c4'])]\n",
    "Y_train_1 = datasets[1].loc[:,'c4'].copy()\n",
    "\n",
    "imp_0 = SimpleImputer(strategy = \"mean\")\n",
    "X_train_0 = imp_0.fit_transform(X_train_0)\n",
    "\n",
    "imp_1 = SimpleImputer(strategy = \"mean\")\n",
    "X_train_1 = imp_1.fit_transform(X_train_1)\n",
    "\n",
    "X_train = np.concatenate((X_train_0,X_train_1))\n",
    "Y_train = np.concatenate((Y_train_0,Y_train_1))\n",
    "\n",
    "# Remove NA from test\n",
    "Test = X_test.copy()\n",
    "Test.loc[:,'c4'] = Y_test\n",
    "Test = Test.dropna()\n",
    "X_test = Test[Test.columns.difference(['c4'])]\n",
    "Y_test = Test.loc[:,'c4'].copy()\n",
    "print('Samples in test set after seperated select:',Counter(Y_test))\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "select = {}\n",
    "select[0] = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "select[1] = Y_train\n",
    "select[2] = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "# Feature selection\n",
    "selected, fs, idx = select_features(select, feature, NN = False)\n",
    "X_train = pd.DataFrame(selected[0])\n",
    "X_test = pd.DataFrame(selected[1])\n",
    "\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = fs.get_support(indices=True)\n",
    "features_df_new = original.iloc[:,cols]\n",
    "pprint(features_df_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model=XGBClassifier(use_label_encoder=False, eta = 0.1,#eta between(0.01-0.2)\n",
    "        max_depth = 9, #values between(3-10)\n",
    "        max_delta_step = 1,\n",
    "        subsample = 0.7,#values between(0.5-1)\n",
    "        colsample_bytree = 0.7,#values between(0.5-1)\n",
    "        tree_method = \"auto\",\n",
    "        #scale_pos_weight = unbalanced,\n",
    "        process_type = \"default\",\n",
    "        num_parallel_tree=3,\n",
    "        objective='multi:softmax',\n",
    "        min_child_weight = 3,\n",
    "        booster='gbtree',\n",
    "#         deterministic_histogram = False,\n",
    "#         sample_type = \"uniform\",\n",
    "        eval_metric = \"mlogloss\",\n",
    "        num_class = n_classes)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "xgb_pred=model.predict(X_test)\n",
    "print(accuracy_score(Y_test, xgb_pred)*100)\n",
    "\n",
    "confusion_matrix_xgb = pd.DataFrame(confusion_matrix(Y_test, xgb_pred))\n",
    "sns.heatmap(confusion_matrix_xgb, annot=True)\n",
    "print(classification_report(Y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "y_train = enc.fit_transform(Y_train[:, np.newaxis]).toarray()\n",
    "y_test = enc.transform(Y_test[:, np.newaxis]).toarray()\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Create model\n",
    "models = [create_custom_model(n_features, n_classes, nodes, n, 'model_{}'.format(n)) \n",
    "          for n in range(layer_1_1, layer_1_2)]\n",
    "\n",
    "# for create_model in models:\n",
    "#     create_model().summary()\n",
    "\n",
    "\n",
    "# Train and save\n",
    "history_dict = {}\n",
    "\n",
    "# TensorBoard Callback\n",
    "cb = TensorBoard()\n",
    "\n",
    "for create_model in models:\n",
    "    model = create_model()\n",
    "    history_callback = model.fit(X_train, y_train,\n",
    "                                 batch_size=bs,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=0,\n",
    "                                 callbacks=[cb])\n",
    "    score = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "    history_dict[model.name] = [history_callback, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for model_name in history_dict:\n",
    "    model = history_dict[model_name][1]\n",
    "    Y_pred = model.predict(X_test)\n",
    "    fpr, tpr, threshold = roc_curve(y_test.ravel(), Y_pred.ravel())\n",
    "\n",
    "    pred.append(Y_pred)\n",
    "\n",
    "x = []\n",
    "for o in range(layer_1_2-layer_1_1):\n",
    "    x.append(pred[o].argmax(axis=-1))\n",
    "\n",
    "true = enc.inverse_transform(y_test)\n",
    "\n",
    "classification_repo(true, x)\n",
    "\n",
    "conf_mat(true, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "pred = []\n",
    "\n",
    "for model_name in history_dict:\n",
    "    model = history_dict[model_name][1]\n",
    "    Y_pred = model.predict(X_test)\n",
    "    fpr, tpr, threshold = roc_curve(y_test.ravel(), Y_pred.ravel())\n",
    "    \n",
    "    pred.append(Y_pred)\n",
    "    \n",
    "    plt.plot(fpr, tpr, label='{}, AUC = {:.3f}'.format(model_name, auc(fpr, tpr)))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();\n",
    "\n",
    "# pred = np.array(pred)\n",
    "# print(pred[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = 'LDA' # 'KNN' or 'LDA'\n",
    "scorings = ['balanced_accuracy', 'roc_auc_ovr', 'roc_auc_ovo', 'accuracy', 'recall']\n",
    "scoring = scorings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select classifier\n",
    "if classify == 'KNN':\n",
    "    clf = KNeighborsClassifier()\n",
    "else:\n",
    "    clf = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, stratify=Y)\n",
    "\n",
    "# X_test_full = X_test\n",
    "\n",
    "# # Remove index\n",
    "# X_train = X_train.drop('index', axis=1)\n",
    "# X_test = X_test.drop('index', axis=1)\n",
    "\n",
    "# # Normalize numeric features\n",
    "# scaler = StandardScaler()\n",
    "# # scaler = MinMaxScaler()\n",
    "# select = {}\n",
    "# select[0] = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "# select[1] = pd.DataFrame(scaler.transform(X_test))\n",
    "# select[2] = Y_train\n",
    "\n",
    "# # Feature selection\n",
    "# select, fs, idx = select_features(select, feature, NN = False)\n",
    "# X_train = select[0]\n",
    "# X_test = select[1]\n",
    "\n",
    "\n",
    "# KNN\n",
    "if classify == 'KNN':\n",
    "    k_range = list(range(1,feature))\n",
    "    weight_options = [\"uniform\", \"distance\"]\n",
    "    grid_params = dict(n_neighbors = k_range, weights = weight_options)\n",
    "    cv = 5\n",
    "\n",
    "# LDA\n",
    "else:\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    cv = 5\n",
    "    grid_params = dict()\n",
    "    grid_params['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "\n",
    "grid = GridSearchCV(clf, grid_params, cv = cv, scoring = scoring, verbose = 1, n_jobs = -1)\n",
    "grid_results = grid.fit(X_train, Y_train)\n",
    "cv_scores = cross_val_score(grid_results.best_estimator_, X_train, Y_train, cv=5)\n",
    "\n",
    "clf = grid_results.best_estimator_\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "probs = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, probs, zero_division = 0))\n",
    "cnf_matrix = pd.DataFrame(confusion_matrix(Y_test, probs))\n",
    "sns.heatmap(cnf_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.random import seed\n",
    "# seed(67)\n",
    "# import tensorflow as tf\n",
    "# tf.random.set_seed(38)\n",
    "# from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# feature = 30\n",
    "# n_classes = 2\n",
    "\n",
    "# # Save original data set\n",
    "# original = X\n",
    "\n",
    "# # Split into training and testing sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, stratify = Y, random_state = 50)\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.15, stratify = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imputation\n",
    "# Train = X_train.copy()\n",
    "# Train.loc[:,'c4'] = Y_train\n",
    "\n",
    "# datasets= {}\n",
    "# by_class = Train.groupby('c4')\n",
    "# for groups, data in by_class:\n",
    "#     datasets[groups] = data\n",
    "\n",
    "# X_train_0 = datasets[0][datasets[0].columns.difference(['c4'])]\n",
    "# Y_train_0 = datasets[0].loc[:,'c4'].copy()\n",
    "# X_train_1 = datasets[1][datasets[1].columns.difference(['c4'])]\n",
    "# Y_train_1 = datasets[1].loc[:,'c4'].copy()\n",
    "\n",
    "# imp_0 = SimpleImputer(strategy = \"most_frequent\")\n",
    "# X_train_0 = imp_0.fit_transform(X_train_0)\n",
    "\n",
    "# imp_1 = SimpleImputer(strategy = \"most_frequent\")\n",
    "# X_train_1 = imp_1.fit_transform(X_train_1)\n",
    "\n",
    "# X_train = np.concatenate((X_train_0,X_train_1))\n",
    "# Y_train = np.concatenate((Y_train_0,Y_train_1))\n",
    "\n",
    "# # Remove NA from test\n",
    "# Test = X_test.copy()\n",
    "# Test.loc[:,'c4'] = Y_test\n",
    "# Test = Test.dropna()\n",
    "# X_test = Test[Test.columns.difference(['c4'])]\n",
    "# Y_test = Test.loc[:,'c4'].copy()\n",
    "# print('Samples in test set after seperated select:',Counter(Y_test))\n",
    "\n",
    "# # Normalize numeric features\n",
    "# scaler = StandardScaler()\n",
    "# # scaler = MinMaxScaler()\n",
    "# select = {}\n",
    "# select[0] = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "# select[1] = Y_train\n",
    "# select[2] = pd.DataFrame(scaler.transform(X_test))\n",
    "# select[3] = pd.DataFrame(scaler.transform(X_val))\n",
    "\n",
    "# # Feature selection\n",
    "# select, fs, idx = select_features(select, feature, NN = True)\n",
    "# X_train = pd.DataFrame(select[0])\n",
    "# X_test = pd.DataFrame(select[1])\n",
    "# X_val = pd.DataFrame(select[2])\n",
    "\n",
    "# # Get columns to keep and create new dataframe with those only\n",
    "# cols = fs.get_support(indices=True)\n",
    "# features_df_new = original.iloc[:,cols]\n",
    "# pprint(features_df_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = fs.get_support(indices=True)\n",
    "features_df_new = original.iloc[:,feature_columns]\n",
    "# pprint(features_df_new.columns)\n",
    "myfeatures = features_df_new.columns\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = myfeatures\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = myfeatures\n",
    "# X_val = pd.DataFrame(X_val)\n",
    "# X_val.columns = myfeatures\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in X_train:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float64))\n",
    "\n",
    "def make_input_fn(data_df, label_df, num_epochs=100, shuffle=False, batch_size=8):\n",
    "    def input_function():\n",
    "        # print(dict(data_df))\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "train_input_fn = make_input_fn(X_train, Y_train)\n",
    "# eval_input_fn = make_input_fn(X_val, Y_val)\n",
    "test_input_fn = make_input_fn(X_test, Y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "# optimizer = 'Ftrl' SGD\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns, model_dir=None, n_classes=n_classes, weight_column=None,\n",
    "    label_vocabulary=None, optimizer='SGD', config=None,\n",
    "    warm_start_from=None,\n",
    "    loss_reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,\n",
    "    sparse_combiner='sum'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.train(train_input_fn)\n",
    "# validation = classifier.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dicts = classifier.predict(test_input_fn)\n",
    "\n",
    "# probs = pd.Series([pred['probabilities'] for pred in pred_dicts])\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "# Y_pred = np.round(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "for prob in probs:\n",
    "    if prob > 0.5: # 0.30 with 50 features #0.27 #prob[1] for full prob\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)\n",
    "            \n",
    "print(Counter(Y_pred))\n",
    "print(Counter(Y_test))\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "confusion_matrix_df = confusion_matrix(Y_test, Y_pred)\n",
    "print(confusion_matrix_df)\n",
    "cnf_matrix = pd.DataFrame(confusion_matrix(Y_test, Y_pred))\n",
    "sns.heatmap(cnf_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(precision_score(Y_test,Y_pred, average='macro'))\n",
    "print(precision_score(Y_test,Y_pred, average='micro'))\n",
    "print(precision_score(Y_test,Y_pred, average='weighted'))\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test,Y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test,Y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test,Y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y_test,Y_pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(Y_test.ravel(), probs.ravel())\n",
    "    \n",
    "plt.plot(fpr, tpr, label='{}, AUC = {:.3f}'.format('LinearClassifier', auc(fpr, tpr)))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_test, probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(0,)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# estimator =tf.estimator.DNNLinearCombinedClassifier(\n",
    "#     model_dir=None, linear_feature_columns=feature_columns, linear_optimizer='SGD',\n",
    "#     dnn_feature_columns=None, dnn_optimizer='Adagrad',\n",
    "#     dnn_hidden_units=None, dnn_activation_fn=tf.nn.relu, dnn_dropout=None,\n",
    "#     n_classes=2, weight_column=None, label_vocabulary=None, config=None,\n",
    "#     warm_start_from=None,\n",
    "#     loss_reduction=tf.compat.v2.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "#     batch_norm=False, linear_sparse_combiner='sum'\n",
    "# ) sparse_softmax_cross_entropy_with_logits\n",
    "\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units = [1024, 512, 256], feature_columns = feature_columns, \n",
    "    model_dir=None, n_classes=n_classes, weight_column=None,\n",
    "    label_vocabulary=None, optimizer='SGD', activation_fn=tf.nn.relu,\n",
    "    dropout=None, config=None, warm_start_from=None,\n",
    "    loss_reduction=tf.compat.v2.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "    batch_norm=False\n",
    ")\n",
    "\n",
    "estimator.train(input_fn=train_input_fn)\n",
    "# validation = estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn=test_input_fn)\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in predictions])\n",
    "# probs = np.array(probs)\n",
    "# Y_pred = np.round(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "for i, prob in enumerate(probs):\n",
    "    if prob > 0.5: # 0.30 with 50 features #0.27\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)\n",
    "\n",
    "print(Counter(Y_pred))\n",
    "print(Counter(Y_test))\n",
    "\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "confusion_matrix_df = confusion_matrix(Y_test, Y_pred)\n",
    "print(confusion_matrix_df)\n",
    "cnf_matrix = pd.DataFrame(confusion_matrix(Y_test, Y_pred))\n",
    "sns.heatmap(cnf_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(Y_test.ravel(), probs.ravel())\n",
    "    \n",
    "plt.plot(fpr, tpr, label='{}, AUC = {:.3f}'.format('DNN', auc(fpr, tpr)))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(precision_score(Y_test,Y_pred, average='macro'))\n",
    "print(precision_score(Y_test,Y_pred, average='micro'))\n",
    "print(precision_score(Y_test,Y_pred, average='weighted'))\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(Y_test,Y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test,Y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test,Y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y_test,Y_pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "confusion_matrix_df = confusion_matrix(Y_test, Y_pred)\n",
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrongs_1 = np.load('wrongs_1.npy', allow_pickle = 'TRUE').item()\n",
    "# wrongs_2 = np.load('wrongs_2.npy', allow_pickle = 'TRUE').item()\n",
    "# one = wrongs_1.copy()\n",
    "# two = dict(list(wrongs_2.items())[0:160])\n",
    "\n",
    "# full_1 = []\n",
    "# for i in range(len(one)):\n",
    "# #     print(one[i])\n",
    "#     full_1 = set(full_1).union(set(one[i]))\n",
    "# # print(len(full_1))\n",
    "# # print(full_1)\n",
    "\n",
    "# full_2 = []\n",
    "# for i in range(len(two)):\n",
    "#     full_2 = set(full_2).union(set(two[i]))\n",
    "# # print(len(full_2))\n",
    "# # print(full_2)\n",
    "\n",
    "# common = set(full_1).intersection(set(full_2))\n",
    "# print(len(common))\n",
    "\n",
    "# subset_c = data.drop(common, axis = 0)\n",
    "# subset_w = data.loc[common]\n",
    "# index_c1 = subset_w.index\n",
    "\n",
    "# print('All', Counter(data['c1']))\n",
    "# print('Correct', Counter(subset_c['c1']))\n",
    "# print('Incorrect', Counter(subset_w['c1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
